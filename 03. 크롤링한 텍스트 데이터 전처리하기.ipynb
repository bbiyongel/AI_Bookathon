{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. 크롤링한 text data를 전처리해서 저장하기\n",
    "- 작성 : 정민정 (https://github.com/jeina7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 지금까지 수집한 모든 plain text 데이터를 일차적으로 전처리한다.\n",
    "\n",
    "\n",
    "- 특정 필요한 특수문자 (`\".\"`, `\",\"` 등의 구두점 등) 를 제외한 다른 특수문자는 모두 제거\n",
    "\n",
    "\n",
    "- 자모음 (`'ㅋㅋㅋ'`, `'ㅜㅜ'` 등) 또한 우리가 생성할 수필 데이터에 부합하지 않으므로 모두 제거\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 현재 디렉토리 상황 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34mCrawling\u001b[00m\r\n",
      "│   └── \u001b[01;34mtextcrawler\u001b[00m\r\n",
      "│       ├── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       └── \u001b[01;34mtext_data\u001b[00m\r\n",
      "├── \u001b[01;34mcommon\u001b[00m\r\n",
      "│   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   ├── \u001b[01;34mmodels\u001b[00m\r\n",
      "│   │   └── \u001b[01;34m345K\u001b[00m\r\n",
      "│   └── \u001b[01;34msrc\u001b[00m\r\n",
      "│       └── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "└── \u001b[01;34mno_use_notebooks\u001b[00m\r\n",
      "\r\n",
      "11 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `common` 은 사전에 학교측에서 제공받은 코드 모음\n",
    "\n",
    "\n",
    "- 우리가 수집한 crawling 코드는 `Crawling` 디렉토리에 있음\n",
    "\n",
    "\n",
    "- 이 중 현재까지 수집한 text 데이터는 `Crawling/textcrawler/text_data` 내에 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.txt       lifeCrawl.csv  sinchun.txt    storyCrawl.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls Crawling/textcrawler/text_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `lifeCrawl.csv`, `storyCrawl.csv`, `sinchun.csv` 세 가지 파일로 존재 (수필 / 소설)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. text를 전처리하는 함수 `PreProcess`\n",
    "- 필요없는 부분 제거\n",
    "- 자모음 제거\n",
    "- `.`, `,`, `'`, `\"`, `?`, `!` 를 제외한 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def PreProcess(text):\n",
    "    text = re.sub(pattern='Posted on [0-9]{4} [0-9]{2} [0-9]{2} .+ Posted in \\S+ \\s?', repl='', string=text)\n",
    "    _filter = re.compile('[ㄱ-ㅣ]+')\n",
    "    text = _filter.sub('', text)\n",
    "    _filter = re.compile('[^가-힣 0-9 a-z A-Z \\. \\, \\' \\\" \\? \\!]+')\n",
    "    text = _filter.sub('', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. 아아 ? '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \".. 아아 ? >>\"\n",
    "PreProcess(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터를 합쳐서 저장하는 함수 `save_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "def save_data(dir_path, save_path):\n",
    "    files = [f for f in glob(dir_path + \"*\", recursive=True)]\n",
    "    \n",
    "    data = ''\n",
    "    \n",
    "    for file in files:\n",
    "        suffix = file.split(\"/\")[-1].split(\".\")[-1]\n",
    "        \n",
    "        if suffix == 'csv':\n",
    "            df = pd.DataFrame.from_csv(file).reset_index()\n",
    "            print('{} data saving. size:'.format(file.split('/')[-1]), df.shape[0])\n",
    "\n",
    "            for i, text in enumerate(df['content'].values):\n",
    "                text = PreProcess(text)\n",
    "                df.loc[i, 'content'] = text\n",
    "\n",
    "            data += \"\\n\".join(df['content'].values)\n",
    "            \n",
    "        elif (suffix == 'txt') and (not file.split(\"/\")[-1].startswith(\"data\")):\n",
    "            print('{} data saving.'.format(file.split('/')[-1]))\n",
    "            with open(file, 'r') as f:\n",
    "                data += f.read()\n",
    "                \n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(data)\n",
    "\n",
    "    print(\"\\nAll saved.\".format(dir_path.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 합칠 데이터와 새로 저장할 데이터 Path 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './Crawling/textcrawler/text_data/'\n",
    "save_path = './Crawling/textcrawler/text_data/data.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 함수 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sinchun.txt data saving.\n",
      "lifeCrawl.csv data saving. size: 2435\n",
      "storyCrawl.csv data saving. size: 3957\n",
      "\n",
      "All saved.\n"
     ]
    }
   ],
   "source": [
    "save_data(dir_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 저장된 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“야, 이 썩을 놈아! 시끄럽다고 몇 번이나 말하노? 어이?”\\n현관문을 부서져라 두드리며 욕할매가 고함을 친다. 나는 그러거나 말거나 문도 열어보지 않는다. 저러다가 시들해져 집에 간 적이 많아 이제 신경도 안 쓴다. 욕할매는 우리 아래층, 401호에 산다. 80살도 넘었다는데 목소리가 어찌나 우렁찬지 밖에서 소리를 지르면 우리 집이 쿵쿵 울리는 것 같다. 우리가 이사 오던 날부터 이삿짐 나르는 사다리차가 시끄럽다고 난리였다.\\n“허구헌 날 다 나뚜고 우짠 일로 이 늦은 시간에 이사를 해 쌌소?”\\n“죄송해요. 저희 부부가 다 일을 다니다 보니 이 시간에 할 수밖에 없네요.”\\n우리가 이사를 하는 시간이 저녁때인 것은 맞다. 하지만 깜깜한 한밤중도 아닌데 뭐 그리 난리 법석을 할 일은 아니다. 욕할매는 이삿짐 나르는데 불쑥 들어와서 한바탕 하고 갔다. 그 일이 있은 후로 우리 집 가훈은 ‘살금살금, 조용조용’이 된 것 같았다.\\n“아래층 할머니 너무 하신 거 아녜요?”\\n엄마는 부엌을 정리하'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(save_path, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data[:500]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
